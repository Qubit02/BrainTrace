"""
brain_graph.py

ë¸Œë ˆì¸ ê·¸ë˜í”„ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” ë¼ìš°í„° ëª¨ë“ˆì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë¸Œë ˆì¸ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ ë° ê´€ë¦¬
- í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ê·¸ë˜í”„ ìƒì„±
- ì§ˆë¬¸-ë‹µë³€ ì‹œìŠ¤í…œ
- ì†ŒìŠ¤ ë°ì´í„° ë©”íŠ¸ë¦­ ë° í†µê³„
- ë…¸ë“œ-ì†ŒìŠ¤ ê´€ê³„ ê´€ë¦¬

ì§€ì›í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸:
- GET /brainGraph/getNodeEdge/{brain_id} : ë¸Œë ˆì¸ì˜ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ
- POST /brainGraph/process_text : í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ê·¸ë˜í”„ ìƒì„±
- POST /brainGraph/answer : ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
- GET /brainGraph/getSourceIds : ë…¸ë“œì˜ ëª¨ë“  source_idì™€ ì œëª© ì¡°íšŒ
- GET /brainGraph/getNodesBySourceId : source_idë¡œ ë…¸ë“œ ì¡°íšŒ
- GET /brainGraph/getSourceDataMetrics/{brain_id} : ë¸Œë ˆì¸ì˜ ì†ŒìŠ¤ë³„ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ
- GET /brainGraph/sourceCount/{brain_id} : ë¸Œë ˆì¸ë³„ ì „ì²´ ì†ŒìŠ¤ ê°œìˆ˜ ì¡°íšŒ
- GET /brainGraph/getSourceContent : ì†ŒìŠ¤ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¡°íšŒ

ê·¸ë˜í”„ ì²˜ë¦¬:
- Neo4j: ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ (ë…¸ë“œ, ì—£ì§€, ê´€ê³„)
- Qdrant: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (ì„ë² ë”© ê²€ìƒ‰)
- AI ëª¨ë¸: GPT/Ollamaë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬

ë°ì´í„°ë² ì´ìŠ¤:
- Neo4j: ê·¸ë˜í”„ ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ
- Qdrant: ë²¡í„° ì„ë² ë”© ì €ì¥ ë° ìœ ì‚¬ë„ ê²€ìƒ‰
- SQLite: ì†ŒìŠ¤ íŒŒì¼ ì •ë³´ ë° ë©”íƒ€ë°ì´í„°

ì˜ì¡´ì„±:
- FastAPI: ì›¹ í”„ë ˆì„ì›Œí¬
- Neo4jHandler: Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…
- embedding_service: ë²¡í„° ì„ë² ë”© ë° ê²€ìƒ‰
- AI ì„œë¹„ìŠ¤: GPT/Ollama ëª¨ë¸ ì—°ë™
- SQLiteHandler: SQLite ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…

ì‘ì„±ì: BrainT ê°œë°œíŒ€
ìµœì¢… ìˆ˜ì •ì¼: 2024ë…„
"""

from fastapi import APIRouter, HTTPException
from models.request_models import ProcessTextRequest, AnswerRequest, GraphResponse
from services import embedding_service
from neo4j_db.Neo4jHandler import Neo4jHandler
import logging
from sqlite_db import SQLiteHandler
from exceptions.custom_exceptions import Neo4jException,AppException, QdrantException
from examples.error_examples import ErrorExamples
from dependencies import get_ai_service_GPT
from dependencies import get_ai_service_Ollama
from services.accuracy_service import compute_accuracy
from services import manual_chunking_sentences
import time

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
router = APIRouter(
    prefix="/brainGraph",
    tags=["brainGraph"],
    responses={404: {"description": "Not found"}}
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ API ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

@router.get(
    "/getNodeEdge/{brain_id}",
    response_model=GraphResponse,
    summary="ë¸Œë ˆì¸ì˜ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ",
    description="íŠ¹ì • ë¸Œë ˆì¸ì˜ ëª¨ë“  ë…¸ë“œì™€ ì—£ì§€(ê´€ê³„) ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
     responses={
        404: ErrorExamples[40401],
        500: ErrorExamples[50001]
    }
    
)
async def get_brain_graph(brain_id: str):
    """
    íŠ¹ì • ë¸Œë ˆì¸ì˜ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì²˜ë¦¬ ê³¼ì •:
    1. brain_idë¡œ Neo4jì—ì„œ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ
    2. ë…¸ë“œì™€ ì—£ì§€ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜
    3. ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ê·¸ë˜í”„ ë°˜í™˜
    
    Args:
        brain_id (str): ê·¸ë˜í”„ë¥¼ ì¡°íšŒí•  ë¸Œë ˆì¸ ID
    
    Returns:
        GraphResponse: ê·¸ë˜í”„ ë°ì´í„°
            - nodes: ë…¸ë“œ ëª©ë¡ (ê° ë…¸ë“œëŠ” name ì†ì„±ì„ ê°€ì§)
            - links: ì—£ì§€ ëª©ë¡ (ê° ì—£ì§€ëŠ” source, target, relation ì†ì„±ì„ ê°€ì§)
    
    Raises:
        Neo4jException: Neo4j ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜
    """
    # ìš”ì²­ ìˆ˜ì‹  ë¡œê¹…: ê´€ì¸¡/ë””ë²„ê¹…ì„ ìœ„í•´ ì£¼ìš” íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë¡
    logging.info(f"getNodeEdge ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ - brain_id: {brain_id}")
    try:
        # ê·¸ë˜í”„ DB í•¸ë“¤ëŸ¬ ìƒì„± (ê° ìš”ì²­ë§ˆë‹¤ ë…ë¦½ ìƒì„±í•˜ì—¬ ì„¸ì…˜ ìˆ˜ëª… ê´€ë¦¬)
        neo4j_handler = Neo4jHandler()
        logging.info("Neo4j í•¸ë“¤ëŸ¬ ìƒì„±ë¨")
        
        # Neo4jì—ì„œ ë¸Œë ˆì¸ ì „ì²´ ê·¸ë˜í”„ ì¡°íšŒ
        graph_data = neo4j_handler.get_brain_graph(brain_id)
        logging.info(f"Neo4jì—ì„œ ë°›ì€ ë°ì´í„°: nodes={len(graph_data['nodes'])}, links={len(graph_data['links'])}")
        
        # if not graph_data['nodes'] and not graph_data['links']:
        #     logging.warning(f"brain_id {brain_id}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        #     raise GraphDataNotFoundException(brain_id)
        
        if not graph_data['nodes'] and not graph_data['links']:
            logging.warning(f"brain_id {brain_id}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        return graph_data
    except AppException as ae:
            raise ae
    except Exception as e:
        logging.error("ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: %s", str(e))
        raise Neo4jException(message=str(e))
        

@router.post("/process_text", 
    summary="í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ê·¸ë˜í”„ ìƒì„±",
    description= """
    í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ, Neo4j ì €ì¥, ë²¡í„° DB ì„ë² ë”©ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    <br> Ollama ì‚¬ìš© â†’ (model: "ollama")  
    <br> GPT ì‚¬ìš© â†’ (model: "gpt")
    """,
    response_description="ì²˜ë¦¬ëœ ë…¸ë“œì™€ ì—£ì§€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
    responses={
        500: ErrorExamples[50001]
    }
    )
async def process_text_endpoint(request_data: ProcessTextRequest):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ, Neo4j ì €ì¥, ë²¡í„° DB ì„ë² ë”©ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    ì²˜ë¦¬ ê³¼ì •:
    1. í…ìŠ¤íŠ¸ ì…ë ¥ ê²€ì¦
    2. AI ëª¨ë¸ ì„ íƒ (GPT ë˜ëŠ” Ollama)
    3. í…ìŠ¤íŠ¸ì—ì„œ ë…¸ë“œì™€ ì—£ì§€ ì¶”ì¶œ
    4. Neo4jì— ê·¸ë˜í”„ ë°ì´í„° ì €ì¥
    5. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì„ë² ë”© ì €ì¥
    6. ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
    
    Args:
        request_data (ProcessTextRequest): í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìš”ì²­
            - text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
            - source_id: ì†ŒìŠ¤ ID
            - brain_id: ë¸Œë ˆì¸ ID
            - model: ì‚¬ìš©í•  ëª¨ë¸ ("gpt" ë˜ëŠ” "ollama")
    
    Returns:
        dict: ì²˜ë¦¬ëœ ë…¸ë“œì™€ ì—£ì§€ ì •ë³´
    
    Raises:
        HTTPException: 
            - 400: í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½
            - 500: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ
    """
    # ìš”ì²­ ë³¸ë¬¸ íŒŒë¼ë¯¸í„° ì–¸íŒ¨í‚¹
    text = request_data.text
    source_id = request_data.source_id
    brain_id = request_data.brain_id
    model = None
    t0 = time.perf_counter()
    # ë¡œê¹…ì€ í¬ë§· ë¬¸ìì—´ì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ê¶Œì¥ë©ë‹ˆë‹¤ (ì—¬ê¸°ì„  ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€)
    logging.info('model : %s', model)
    if not text:
        raise HTTPException(status_code=400, detail="text íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if not source_id:
        raise HTTPException(status_code=400, detail="source_id íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if not brain_id:
        raise HTTPException(status_code=400, detail="brain_id íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ë³´ì•ˆ/í”„ë¼ì´ë²„ì‹œ ê³ ë ¤: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì›ë¬¸ ì „ì²´ë¥¼ ë¡œê·¸ì— ë‚¨ê¸°ì§€ ì•ŠëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
    logging.info("ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸: %s, source_id: %s, brain_id: %s", text, source_id, brain_id)
    
    # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ AI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì£¼ì…
    if model == "gpt":
        ai_service = get_ai_service_GPT()
    elif model == "ollama":
        ai_service = get_ai_service_Ollama()
    else:
        ai_service=None

    # Step 1: í…ìŠ¤íŠ¸ì—ì„œ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ (AI ì„œë¹„ìŠ¤)
    if ai_service==None:
        # ê¸°ë³¸ ìˆ˜ë™ ì²­í¬ ì²˜ë¦¬: ëª¨ë¸ ë¯¸ì„ íƒ ì‹œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ
        nodes, edges=manual_chunking_sentences.extract_graph_components(text, (brain_id, source_id))
    else:
        # ì„ íƒëœ AI ì„œë¹„ìŠ¤ê°€ ì œê³µí•˜ëŠ” ì¶”ì¶œ ë¡œì§ í˜¸ì¶œ
        nodes, edges = ai_service.extract_graph_components(text, source_id)
    logging.info("ì¶”ì¶œëœ ë…¸ë“œ: %s", nodes)
    logging.info("ì¶”ì¶œëœ ì—£ì§€: %s", edges)

    # Step 2: Neo4jì— ë…¸ë“œì™€ ì—£ì§€ ì €ì¥ 
    neo4j_handler = Neo4jHandler()
    neo4j_handler.insert_nodes_and_edges(nodes, edges, brain_id)
    logging.info("Neo4jì— ë…¸ë“œì™€ ì—£ì§€ ì‚½ì… ì™„ë£Œ")

    # Step 3: ë…¸ë“œ ì •ë³´ë¥¼ ë²¡í„° DBì— ì„ë² ë”©
    # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    if not embedding_service.is_index_ready(brain_id):
        embedding_service.initialize_collection(brain_id)
    
    # ë…¸ë“œ ì •ë³´ ì„ë² ë”© ë° ì €ì¥
    # - ê° ë…¸ë“œ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ì—¬ Qdrantì— upsert
    # embedding_service.update_index_and_get_embeddings(nodes, brain_id)
    # logging.info("ë²¡í„° DBì— ë…¸ë“œ ì„ë² ë”© ì €ì¥ ì™„ë£Œ")
    dur_ms = (time.perf_counter() - t0) * 1000
    logging.info("ì‹œê°„@@@@@@ %.3f s @@@@@@", dur_ms / 1000)

    return {
        "message": "í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ, ê·¸ë˜í”„(ë…¸ë“œì™€ ì—£ì§€)ê°€ ìƒì„±ë˜ì—ˆê³  ë²¡í„° DBì— ì„ë² ë”©ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "nodes": nodes,
        "edges": edges
    }


@router.post("/answer",
    summary="ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±",
    description="""
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ ì„ë² ë”©ì„ í†µí•´ ìœ ì‚¬í•œ ë…¸ë“œë¥¼ ì°¾ê³ , 
    í•´ë‹¹ ë…¸ë“œë“¤ì˜ 2ë‹¨ê³„ ê¹Šì´ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œ í›„ LLMì„ ì´ìš©í•´ ìµœì¢… ë‹µë³€ ìƒì„±
    <br> Ollama ì‚¬ìš© â†’ (model: "ollama")  
    <br> GPT ì‚¬ìš© â†’ (model: "gpt")
    """,
    response_description="ìƒì„±ëœ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
    responses={
    500: {
        "description": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ (50001, 50002 ë“±)",
        "content": {
            "application/json": {
                "examples": {
                    "50001": ErrorExamples[50001]["content"]["application/json"],
                    "50002": ErrorExamples[50002]["content"]["application/json"]
                }
            }
        }
    }
}
)
async def answer_endpoint(request_data: AnswerRequest):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ ì„ë² ë”©ì„ í†µí•´ ìœ ì‚¬í•œ ë…¸ë“œë¥¼ ì°¾ê³ , 
    í•´ë‹¹ ë…¸ë“œë“¤ì˜ 2ë‹¨ê³„ ê¹Šì´ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œ í›„ LLMì„ ì´ìš©í•´ ìµœì¢… ë‹µë³€ ìƒì„±
    <br> Ollama ì‚¬ìš© â†’ (model: "ollama")  
    <br> GPT ì‚¬ìš© â†’ (model: "gpt")
    """
    # ìš”ì²­ íŒŒë¼ë¯¸í„° ì–¸íŒ¨í‚¹ ë° ê¸°ë³¸ ê²€ì¦
    question = request_data.question
    session_id = request_data.session_id
    brain_id = str(request_data.brain_id)  # ë¬¸ìì—´ë¡œ ë³€í™˜
    model = request_data.model
    model_name = request_data.model_name
    if not question:
        raise HTTPException(status_code=400, detail="question íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if not brain_id:
        raise HTTPException(status_code=400, detail="brain_id íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
     # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ AI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì£¼ì…
    if model == "openai":
        logging.info("ğŸš€ OpenAI ì„œë¹„ìŠ¤ ì„ íƒë¨ - model_name: %s", model_name)
        ai_service = get_ai_service_GPT(model_name)  # model_name ì „ë‹¬
        logging.info("ğŸš€ OpenAI ì„œë¹„ìŠ¤ ìƒì„± ì™„ë£Œ")
    elif model == "ollama":
        logging.info("ğŸš€ Ollama ì„œë¹„ìŠ¤ ì„ íƒë¨ - model_name: %s", model_name)
        ai_service = get_ai_service_Ollama(model_name)
        logging.info("ğŸš€ Ollama ì„œë¹„ìŠ¤ ìƒì„± ì™„ë£Œ")
    else:
        logging.error("ğŸš€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: %s", model)
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model}")
    
    # ğŸš€ í•µì‹¬ ë””ë²„ê¹…: ëª¨ë¸ ì •ë³´ í™•ì¸
    logging.info("ğŸš€ === ëª¨ë¸ ì •ë³´ ===")
    logging.info("ğŸš€ ìš”ì²­ëœ model: %s, model_name: %s", model, model_name)
    logging.info("ğŸš€ AI ì„œë¹„ìŠ¤ íƒ€ì…: %s", type(ai_service).__name__)
    if hasattr(ai_service, 'model_name'):
        logging.info("ğŸš€ ì‹¤ì œ ì‚¬ìš©í•  ëª¨ë¸: %s", ai_service.model_name)
    
    try:
        # SQLite í•¸ë“¤ëŸ¬: ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„°(title ë“±) ì¡°íšŒì™€ ì±„íŒ… ë¡œê·¸ ì €ì¥ì— ì‚¬ìš©
        db_handler = SQLiteHandler()
        
        # Step 1: ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if not embedding_service.is_index_ready(brain_id):
            embedding_service.initialize_collection(brain_id)
            logging.info("Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ: %s", brain_id)
        
        # Step 2: ì§ˆë¬¸ ì„ë² ë”© ê³„ì‚°
        question_embedding = embedding_service.encode_text(question)
        
        # Step 3: ì„ë² ë”©ì„ í†µí•´ ìœ ì‚¬í•œ ë…¸ë“œ ê²€ìƒ‰, QëŠ” ê²€ìƒ‰ëœ ë…¸ë“œì™€ ì§ˆë¬¸ì˜ ìœ ì‚¬ë„ í‰ê· ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚°ì— ì“°ì„
        similar_nodes,Q = embedding_service.search_similar_nodes(embedding=question_embedding, brain_id=brain_id)
        if not similar_nodes:
            raise QdrantException("ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë…¸ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # ë…¸ë“œ ì´ë¦„ë§Œ ì¶”ì¶œ
        similar_node_names = [node["name"] for node in similar_nodes]
        logging.info("sim node name: %s", similar_node_names)
        logging.info("sim node score: %s", [f"{node['name']}:{node['score']:.2f}" for node in similar_nodes])
        
        # Step 4: ìœ ì‚¬í•œ ë…¸ë“œë“¤ì˜ 1*ë‹¨ê³„ ê¹Šì´ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        neo4j_handler = Neo4jHandler()
        result = neo4j_handler.query_schema_by_node_names(similar_node_names, brain_id)
        if not result:
            raise Neo4jException("ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        logging.info("### Neo4j ì¡°íšŒ ê²°ê³¼ ì „ì²´: %s", result)
        
        # ê²°ê³¼ë¥¼ ì¦‰ì‹œ ì²˜ë¦¬
        nodes_result = result.get("nodes", [])
        related_nodes_result = result.get("relatedNodes", [])
        relationships_result = result.get("relationships", [])
        
        logging.info("Neo4j search result: nodes=%d, related_nodes=%d, relationships=%d", 
                   len(nodes_result), len(related_nodes_result), len(relationships_result))
        
        # Step 5: ìŠ¤í‚¤ë§ˆ ê°„ê²°í™” ë° í…ìŠ¤íŠ¸ êµ¬ì„±
        # - ëª¨ë¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ìŠ¤í‚¤ë§ˆë¥¼ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½/ì •ë¦¬
        raw_schema_text = ai_service.generate_schema_text(nodes_result, related_nodes_result, relationships_result)
        
        # Step 6: LLMì„ì„ ì‚¬ìš©í•´ ìµœì¢… ë‹µë³€ ìƒì„±
        logging.info("ğŸš€ ë‹µë³€ ìƒì„± ì‹œì‘ - ëª¨ë¸: %s", ai_service.model_name if hasattr(ai_service, 'model_name') else 'ì•Œ ìˆ˜ ì—†ìŒ')
        final_answer = ai_service.generate_answer(raw_schema_text, question)
        referenced_nodes = ai_service.extract_referenced_nodes(final_answer)
        final_answer = final_answer.split("EOF")[0].strip()
        
        # referenced_nodes ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ final_answer ë’¤ì— ì¶”ê°€
        if referenced_nodes:
            nodes_text = "\n\n[ì°¸ê³ ëœ ë…¸ë“œ ëª©ë¡]\n" + "\n".join(f"- {node}" for node in referenced_nodes)
            final_answer += nodes_text
        # ê°„ë‹¨ ì •í™•ë„ ì‚°ì¶œ: ë‹µë³€/ì°¸ê³ ë…¸ë“œ/ë¸Œë ˆì¸/ìŠ¤í‚¤ë§ˆ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§€í‘œ
        accuracy = compute_accuracy(final_answer,referenced_nodes,brain_id,Q,raw_schema_text)
        logging.info(f"ì •í™•ë„ : {accuracy}")
        # nodeì˜ ì¶œì²˜ ì†ŒìŠ¤ idë“¤ ê°€ì ¸ì˜¤ê¸°
        node_to_ids = neo4j_handler.get_descriptions_bulk(referenced_nodes, brain_id)
        logging.info(f"node_to_ids: {node_to_ids}")
        # ëª¨ë“  source_id ì§‘í•© ìˆ˜ì§‘
        all_ids = sorted({sid for ids in node_to_ids.values() for sid in ids})
        logging.info(f"all_ids: {all_ids}")
        # SQLite batch ì¡°íšŒë¡œ idâ†’title ë§¤í•‘
        id_to_title = db_handler.get_titles_by_ids(all_ids)
               
        # ìµœì¢… êµ¬ì¡°í™”
        enriched = []
        for node in referenced_nodes:
            # ì¤‘ë³µ ì œê±°ëœ source_id ë¦¬ìŠ¤íŠ¸
            unique_sids = list(dict.fromkeys(node_to_ids.get(node, [])))
            sources = []
            for sid in unique_sids:
                if sid not in id_to_title:
                    continue
                # Neo4j ì—ì„œ ì´ (node, sid) ì¡°í•©ì˜ original_sentences ê°€ì ¸ì˜¤ê¸°
                orig_sents = neo4j_handler.get_original_sentences(node, sid, brain_id)

                sources.append({
                    "id": str(sid),
                    "title": id_to_title[sid],
                    "original_sentences": orig_sents  # ì—¬ê¸°ì— ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë“¤ì–´ê°
                })

            enriched.append({
                    "name": node,
                    "source_ids": sources
            })

        # AI ë‹µë³€ ì €ì¥ ë° chat_id íšë“
        chat_id = db_handler.save_chat(session_id, True, final_answer, enriched, accuracy)

        return {
            "answer": final_answer,
            "referenced_nodes": enriched,
            "chat_id": chat_id,
            "accuracy": accuracy
        }
    except Exception as e:
        logging.error("answer ì˜¤ë¥˜: %s", str(e))
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/getSourceIds",
    summary="ë…¸ë“œì˜ ëª¨ë“  source_idì™€ ì œëª©ì„ ì¡°íšŒ",
    description="íŠ¹ì • ë…¸ë“œì˜ descriptions ë°°ì—´ì—ì„œ ëª¨ë“  source_idë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_description="source_idì™€ titleì„ í¬í•¨í•˜ëŠ” ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
    responses={
    500: ErrorExamples[50002]
    }
)
async def get_source_ids(node_name: str, brain_id: str):
    """
    ë…¸ë“œì˜ ëª¨ë“  source_idì™€ ì œëª©ì„ ë°˜í™˜í•©ë‹ˆë‹¤:
    
    - **node_name**: ì¡°íšŒí•  ë…¸ë“œì˜ ì´ë¦„
    - **brain_id**: ë¸Œë ˆì¸ ID
    
    ë°˜í™˜ê°’:
    - **sources**: source_idì™€ titleì„ í¬í•¨í•˜ëŠ” ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    # íŒŒë¼ë¯¸í„° ê¸°ë¡: ìš´ì˜ ë””ë²„ê¹… ì‹œ í™œìš©
    logging.info(f"getSourceIds ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ - node_name: {node_name}, brain_id: {brain_id}")
    try:
        neo4j_handler = Neo4jHandler()
        db = SQLiteHandler()
        logging.info("Neo4j í•¸ë“¤ëŸ¬ ìƒì„±ë¨")
        
        # Neo4jì—ì„œ ë…¸ë“œì˜ descriptions ë°°ì—´ ì¡°íšŒ
        descriptions = neo4j_handler.get_node_descriptions(node_name, brain_id)
        if not descriptions:
            return {"sources": []}
            
        # descriptions ë°°ì—´ì—ì„œ ëª¨ë“  source_id ì¶”ì¶œ
        # - JSON í•­ëª© ê°„ ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©
        seen_ids = set()
        sources = []
        
        for desc in descriptions:
            if "source_id" in desc:
                source_id = desc["source_id"]
                if source_id not in seen_ids:
                    seen_ids.add(source_id)
                    
                    # PDFì™€ TextFile í…Œì´ë¸”ì—ì„œ ëª¨ë‘ ì¡°íšŒ
                    pdf = db.get_pdf(int(source_id))
                    textfile = db.get_textfile(int(source_id))
                    memo = db.get_memo(int(source_id))
                    md = db.get_mdfile(int(source_id))
                    
                    title = None
                    if pdf:
                        title = pdf['pdf_title']
                    elif textfile:
                        title = textfile['txt_title']
                    elif memo:
                        title = memo['memo_title']
                    elif md:
                        title = md['md_title']
                    
                    if title:
                        sources.append({
                            "id": source_id,
                            "title": title
                        })
        
        logging.info(f"ì¶”ì¶œëœ sources: {sources}")
        return {"sources": sources}
        
    except Exception as e:
        logging.error("source_id ì¡°íšŒ ì˜¤ë¥˜: %s", str(e))
        raise HTTPException(status_code=500, detail=f"source_id ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/getNodesBySourceId",
    summary="source_idë¡œ ë…¸ë“œ ì¡°íšŒ",
    description="íŠ¹ì • source_idê°€ descriptionsì— í¬í•¨ëœ ëª¨ë“  ë…¸ë“œì˜ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_description="ë…¸ë“œ ì´ë¦„ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_nodes_by_source_id(source_id: str, brain_id: str):
    """
    source_idë¡œ ë…¸ë“œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤:
    
    - **source_id**: ì°¾ì„ source_id
    - **brain_id**: ë¸Œë ˆì¸ ID
    
    ë°˜í™˜ê°’:
    - **nodes**: ë…¸ë“œ ì´ë¦„ ëª©ë¡
    """
    logging.info(f"getNodesBySourceId ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ - source_id: {source_id}, brain_id: {brain_id}")
    try:
        # ê·¸ë˜í”„ DBì—ì„œ source_idê°€ í¬í•¨ëœ ë…¸ë“œ ì¡°íšŒ
        neo4j_handler = Neo4jHandler()
        logging.info("Neo4j í•¸ë“¤ëŸ¬ ìƒì„±ë¨")
        
        # Neo4jì—ì„œ source_idë¡œ ë…¸ë“œ ì¡°íšŒ
        node_names = neo4j_handler.get_nodes_by_source_id(source_id, brain_id)
        logging.info(f"ì¡°íšŒëœ ë…¸ë“œ ì´ë¦„: {node_names}")
        
        return {"nodes": node_names}
        
    except Exception as e:
        logging.error("ë…¸ë“œ ì¡°íšŒ ì˜¤ë¥˜: %s", str(e))
        raise HTTPException(status_code=500, detail=f"ë…¸ë“œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/getSourceDataMetrics/{brain_id}",
    summary="ë¸Œë ˆì¸ì˜ ì†ŒìŠ¤ë³„ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ",
    description="íŠ¹ì • ë¸Œë ˆì¸ì˜ ëª¨ë“  ì†ŒìŠ¤ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì–‘ê³¼ ê·¸ë˜í”„ ë°ì´í„° ì–‘ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_description="ì†ŒìŠ¤ë³„ í…ìŠ¤íŠ¸ ì–‘ê³¼ ê·¸ë˜í”„ ë°ì´í„° ì–‘ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
    responses={
        404: ErrorExamples[40401],
        500: ErrorExamples[50001]
    }
)
async def get_source_data_metrics(brain_id: str):
    """
    íŠ¹ì • ë¸Œë ˆì¸ì˜ ëª¨ë“  ì†ŒìŠ¤ì— ëŒ€í•œ ë°ì´í„° ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤:
    
    - **brain_id**: ë©”íŠ¸ë¦­ì„ ì¡°íšŒí•  ë¸Œë ˆì¸ ID
    
    ë°˜í™˜ê°’:
    - **total_text_length**: ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´
    - **total_nodes**: ì „ì²´ ë…¸ë“œ ìˆ˜
    - **total_edges**: ì „ì²´ ì—£ì§€ ìˆ˜
    - **source_metrics**: ì†ŒìŠ¤ë³„ ìƒì„¸ ë©”íŠ¸ë¦­
    """
    logging.info(f"getSourceDataMetrics ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ - brain_id: {brain_id}")
    try:
        neo4j_handler = Neo4jHandler()
        db_handler = SQLiteHandler()
        
        # 1. Neo4jì—ì„œ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ
        graph_data = neo4j_handler.get_brain_graph(brain_id)
        total_nodes = len(graph_data.get('nodes', []))
        total_edges = len(graph_data.get('links', []))
        
        # 2. SQLiteì—ì„œ ì†ŒìŠ¤ë³„ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
        source_metrics = []
        total_text_length = 0
        
        # PDF ì†ŒìŠ¤ë“¤ ì¡°íšŒ
        pdfs = db_handler.get_pdfs_by_brain(brain_id)
        for pdf in pdfs:
            try:
                # PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨í•œ ì¶”ì •)
                # ì‹¤ì œë¡œëŠ” PDF íŒŒì‹±ì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” íŒŒì¼ í¬ê¸°ë¡œ ì¶”ì •
                import os
                if os.path.exists(pdf['pdf_path']):
                    file_size = os.path.getsize(pdf['pdf_path'])
                    # PDF íŒŒì¼ í¬ê¸°ë¥¼ í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ì¶”ì • (ëŒ€ëµì ì¸ ê³„ì‚°)
                    estimated_text_length = int(file_size * 0.1)  # PDFì˜ ì•½ 10%ê°€ í…ìŠ¤íŠ¸ë¼ê³  ê°€ì •
                else:
                    estimated_text_length = 0
                
                # ì´ PDFì—ì„œ ìƒì„±ëœ ë…¸ë“œ ìˆ˜ ê³„ì‚°
                pdf_nodes = neo4j_handler.get_nodes_by_source_id(pdf['pdf_id'], brain_id)
                pdf_edges = neo4j_handler.get_edges_by_source_id(pdf['pdf_id'], brain_id)
                
                source_metrics.append({
                    "source_id": pdf['pdf_id'],
                    "source_type": "pdf",
                    "title": pdf['pdf_title'],
                    "text_length": estimated_text_length,
                    "nodes_count": len(pdf_nodes),
                    "edges_count": len(pdf_edges)
                })
                
                total_text_length += estimated_text_length
                
            except Exception as e:
                logging.error(f"PDF ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜ (ID: {pdf['pdf_id']}): {str(e)}")
        
        # TXT ì†ŒìŠ¤ë“¤ ì¡°íšŒ
        txts = db_handler.get_textfiles_by_brain(brain_id)
        for txt in txts:
            try:
                # TXT íŒŒì¼ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
                import os
                if os.path.exists(txt['txt_path']):
                    with open(txt['txt_path'], 'r', encoding='utf-8') as f:
                        text_content = f.read()
                        text_length = len(text_content)
                else:
                    text_length = 0
                
                # ì´ TXTì—ì„œ ìƒì„±ëœ ë…¸ë“œ ìˆ˜ ê³„ì‚°
                txt_nodes = neo4j_handler.get_nodes_by_source_id(txt['txt_id'], brain_id)
                txt_edges = neo4j_handler.get_edges_by_source_id(txt['txt_id'], brain_id)
                
                source_metrics.append({
                    "source_id": txt['txt_id'],
                    "source_type": "txt",
                    "title": txt['txt_title'],
                    "text_length": text_length,
                    "nodes_count": len(txt_nodes),
                    "edges_count": len(txt_edges)
                })
                
                total_text_length += text_length
                
            except Exception as e:
                logging.error(f"TXT ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜ (ID: {txt['txt_id']}): {str(e)}")
        
        # MEMO ì†ŒìŠ¤ë“¤ ì¡°íšŒ
        memos = db_handler.get_memos_by_brain(brain_id, is_source=True)
        for memo in memos:
            try:
                # ë©”ëª¨ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
                text_length = len(memo['memo_text'] or '')
                
                # ì´ ë©”ëª¨ì—ì„œ ìƒì„±ëœ ë…¸ë“œ ìˆ˜ ê³„ì‚°
                memo_nodes = neo4j_handler.get_nodes_by_source_id(memo['memo_id'], brain_id)
                memo_edges = neo4j_handler.get_edges_by_source_id(memo['memo_id'], brain_id)
                
                source_metrics.append({
                    "source_id": memo['memo_id'],
                    "source_type": "memo",
                    "title": memo['memo_title'],
                    "text_length": text_length,
                    "nodes_count": len(memo_nodes),
                    "edges_count": len(memo_edges)
                })
                
                total_text_length += text_length
                
            except Exception as e:
                logging.error(f"MEMO ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜ (ID: {memo['memo_id']}): {str(e)}")
        
        return {
            "total_text_length": total_text_length,
            "total_nodes": total_nodes,
            "total_edges": total_edges,
            "source_metrics": source_metrics
        }
        
    except AppException as ae:
        raise ae
    except Exception as e:
        logging.error("ì†ŒìŠ¤ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ ì˜¤ë¥˜: %s", str(e))
        raise Neo4jException(message=str(e))

@router.get("/sourceCount/{brain_id}", summary="ë¸Œë ˆì¸ë³„ ì „ì²´ ì†ŒìŠ¤ ê°œìˆ˜ ì¡°íšŒ", description="íŠ¹ì • ë¸Œë ˆì¸ì— ì†í•œ PDF, TXT, MD, MEMO ì†ŒìŠ¤ì˜ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_source_count(brain_id: int):
    """
    í•´ë‹¹ brain_idì— ì†í•œ ëª¨ë“  ì†ŒìŠ¤(PDF, TXT, MD, MEMO) ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    is_sourceê°€ trueì¸ ë©”ëª¨ë§Œ ì†ŒìŠ¤ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    db = SQLiteHandler()
    try:
        pdfs = db.get_pdfs_by_brain(brain_id)
        txts = db.get_textfiles_by_brain(brain_id)
        mds = db.get_mds_by_brain(brain_id)
        memos = db.get_memos_by_brain(brain_id, is_source=True)  # is_sourceê°€ Trueì¸ ë©”ëª¨ë§Œ ì¡°íšŒ
        total_count = len(pdfs) + len(txts) + len(mds) + len(memos)
        return {
            "pdf_count": len(pdfs),
            "txt_count": len(txts),
            "md_count": len(mds),
            "memo_count": len(memos),
            "total_count": total_count
        }
    except Exception as e:
        raise HTTPException(500, f"ì†ŒìŠ¤ ê°œìˆ˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@router.get("/getSourceContent",
    summary="ì†ŒìŠ¤ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¡°íšŒ",
    description="íŠ¹ì • source_idì˜ íŒŒì¼ íƒ€ì…ì— ë”°ë¼ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
    response_description="ì†ŒìŠ¤ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
    responses={
        404: ErrorExamples[40401],
        500: ErrorExamples[50001]
    }
)
async def get_source_content(source_id: str, brain_id: str):
    """
    ì†ŒìŠ¤ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¡°íšŒí•©ë‹ˆë‹¤:
    
    - **source_id**: ì¡°íšŒí•  ì†ŒìŠ¤ ID
    - **brain_id**: ë¸Œë ˆì¸ ID
    
    ë°˜í™˜ê°’:
    - **content**: ì†ŒìŠ¤ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©
    - **title**: ì†ŒìŠ¤ íŒŒì¼ì˜ ì œëª©
    - **type**: íŒŒì¼ íƒ€ì… (pdf, textfile, memo, md, docx)
    """
    logging.info(f"getSourceContent ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨ - source_id: {source_id}, brain_id: {brain_id}")
    try:
        db = SQLiteHandler()
        
        # PDFì™€ TextFile, Memo, MD, DocsFile í…Œì´ë¸”ì—ì„œ ëª¨ë‘ ì¡°íšŒ
        pdf = db.get_pdf(int(source_id))
        textfile = db.get_textfile(int(source_id))
        memo = db.get_memo(int(source_id))
        md = db.get_mdfile(int(source_id))
        docx = db.get_docxfile(int(source_id))
        
        content = None
        title = None
        file_type = None
        
        if pdf:
            content = pdf.get('pdf_text', '')
            title = pdf.get('pdf_title', '')
            file_type = 'pdf'
        elif textfile:
            content = textfile.get('txt_text', '')
            title = textfile.get('txt_title', '')
            file_type = 'textfile'
        elif memo:
            content = memo.get('memo_text', '')
            title = memo.get('memo_title', '')
            file_type = 'memo'
        elif md:
            content = md.get('md_text', '')
            title = md.get('md_title', '')
            file_type = 'md'
        elif docx:
            content = docx.get('docx_text', '')
            title = docx.get('docx_title', '')
            file_type = 'docx'
        
        if content is None:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ source_idì˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            "content": content,
            "title": title,
            "type": file_type
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error("ì†ŒìŠ¤ ë‚´ìš© ì¡°íšŒ ì˜¤ë¥˜: %s", str(e))
        raise HTTPException(status_code=500, detail=f"ì†ŒìŠ¤ ë‚´ìš© ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")