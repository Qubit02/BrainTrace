# ì§€ì‹ê·¸ë˜í”„(Knowledge Graph) ìƒì„¸ ì„¤ëª…

## ğŸ“‹ ëª©ì°¨

<details>
<summary><b>1. ì§€ì‹ê·¸ë˜í”„ë€ ë¬´ì—‡ì¸ê°€?</b></summary>
<div markdown="1">

### 1.1 ì§€ì‹ê·¸ë˜í”„ì˜ ì •ì˜

ì§€ì‹ ê·¸ë˜í”„ëŠ” ê´€ë ¨ ìˆëŠ” ì •ë³´ë¥¼ ì„œë¡œ ì—°ê²°ëœ ê·¸ë˜í”„ í˜•íƒœë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ í†µí•©í•˜ê³  ì—°ê²°í•´ ì‚¬ìš©ìì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ë¹ ë¥¸ ì •ë³´ ê²€ìƒ‰ê³¼ ì¶”ë¡ ì„ ì§€ì›í•©ë‹ˆë‹¤. ê°œì¸í™”ëœ ì¸ê³µì§€ëŠ¥(AI)ì„ êµ¬í˜„í•˜ëŠ” í•µì‹¬ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ê¼½í™ë‹ˆë‹¤.

ì§€ì‹ ê·¸ë˜í”„ëŠ” ì •ë³´ë¥¼ **ë…¸ë“œ(ê°œì²´)**ì™€ **ì—£ì§€(ê´€ê³„)**ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ë°ì´í„° ê°„ì˜ ê´€ê³„ì™€ ë§¥ë½ì„ ì´í•´í•˜ê³ , ìƒˆë¡œìš´ ì§€ì‹ì„ ì¶”ë¡ í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì˜ í•œ ìœ í˜•ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•˜ê³  ì˜ë¯¸ ìˆëŠ” ì—°ê´€ì„±ì„ ë°œê²¬í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

### 1.2 ì§€ì‹ê·¸ë˜í”„ì˜ êµ¬ì„± ìš”ì†Œ

#### ë…¸ë“œ(Node)
- **ì •ì˜**: ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ í•µì‹¬ ê°œë…ì´ë‚˜ ê°œì²´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
- **BrainTì—ì„œì˜ ì—­í• **: AI ëª¨ë¸ì´ë‚˜ ìˆ˜ë™ ì²­í‚¹ì„ í†µí•´ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ ê°œë…ë“¤ì„ ë…¸ë“œë¡œ ì¶”ì¶œ
- **ì†ì„±**: `name`(ê°œì²´ëª…), `label`(ë¶„ë¥˜), `description`(ì„¤ëª…) ë“±

#### ì—£ì§€(Edge)
- **ì •ì˜**: ë…¸ë“œ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
- **BrainTì—ì„œì˜ ì—­í• **: "í¬í•¨í•˜ë‹¤", "ê´€ë ¨ë˜ë‹¤", "ì˜í–¥ì„ ì£¼ë‹¤" ë“±ì˜ ê´€ê³„ë¥¼ ì—£ì§€ë¡œ í‘œí˜„
- **ì†ì„±**: `source`(ì‹œì‘ ë…¸ë“œ), `target`(ë„ì°© ë…¸ë“œ), `relation`(ê´€ê³„ ìœ í˜•)

#### ì†ì„±(Properties)
- **ì •ì˜**: ë…¸ë“œì™€ ì—£ì§€ì— ì¶”ê°€ë˜ëŠ” ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤
- **BrainTì—ì„œì˜ ì—­í• **: `source_id`(ì¶œì²˜ ë¬¸ì„œ), `original_sentences`(ì›ë¬¸ ë¬¸ì¥), `descriptions`(ë‹¤ì¤‘ ì„¤ëª…) ë“±ì˜ ì†ì„±ì„ ê´€ë¦¬

### 1.3 ì§€ì‹ê·¸ë˜í”„ì˜ ì¥ì 

#### 1.3.1 ì˜ë¯¸ì  ë°ì´í„° í†µí•©
- ë‹¤ì–‘í•œ ì¶œì²˜ì˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ê³ , ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì˜ˆ: ì—¬ëŸ¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ "Apple"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ìˆì„ ë•Œ, ì§€ì‹ ê·¸ë˜í”„ëŠ” ë¬¸ë§¥ì— ë”°ë¼ "ì‚¬ê³¼"ì™€ "ì• í”Œì‚¬"ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

#### 1.3.2 ê°•ë ¥í•œ ê²€ìƒ‰ ë° ì§ˆì˜
- ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì˜ˆ: "ì…°ìµìŠ¤í”¼ì–´ì˜ ì‘í’ˆ ì¤‘ ì˜í™”ë¡œ ì œì‘ëœ ê²ƒì€?" ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´ ì§€ì‹ ê·¸ë˜í”„ëŠ” ê´€ë ¨ëœ ì •ë³´ë¥¼ ì—°ê²°í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

#### 1.3.3 ì¶”ë¡ ê³¼ ë°œê²¬
- ë°ì´í„°ë¥¼ ë‹¨ìˆœíˆ ì €ì¥í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼, ë°ì´í„° ê°„ì˜ ê´€ê³„ë¥¼ í†µí•´ ìƒˆë¡œìš´ ì§€ì‹ì„ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì˜ˆ: ìƒˆë¡œìš´ í•™ìˆ  ë…¼ë¬¸ì´ ì¶”ê°€ë˜ë©´, ê¸°ì¡´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±ì„ í†µí•´ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

#### 1.3.4 ë°ì´í„°ì˜ ì¬ì‚¬ìš©ê³¼ ìƒí˜¸ ìš´ìš©ì„±
- ë°ì´í„° ëª¨ë¸ì´ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•˜ì—¬ ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì‰½ê²Œ ì¬ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì˜ˆ: ê±´ê°•, ê¸ˆìœµ, êµìœ¡ ë“± ì—¬ëŸ¬ ë„ë©”ì¸ì—ì„œ ë™ì¼í•œ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

</div>
</details>

<details>
<summary><b>2. BrainTì—ì„œ ì§€ì‹ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ </b></summary>
<div markdown="1">

### 2.1 ê¸°ì¡´ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ í•œê³„

#### 2.1.1 í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì˜ ë¬¸ì œì 
- **ì •í™•ë„ ë¶€ì¡±**: ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¸í•œ ë¶€ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼
- **ë§¥ë½ ì´í•´ ë¶€ì¡±**: ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì œëŒ€ë¡œ íŒŒì•…í•˜ì§€ ëª»í•¨
- **ê´€ë ¨ì„± ë¶€ì¡±**: í‚¤ì›Œë“œê°€ ê°™ì§€ë§Œ ì˜ë¯¸ê°€ ë‹¤ë¥¸ ê²½ìš°ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•¨

#### 2.1.2 ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰ì˜ í•œê³„
- **êµ¬ì¡°í™” ë¶€ì¡±**: ë¬¸ì„œ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ì§€ ëª»í•¨
- **ì¬ì‚¬ìš©ì„± ë¶€ì¡±**: í•œ ë²ˆ ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ë‹¤ë¥¸ ë§¥ë½ì—ì„œ í™œìš©í•˜ê¸° ì–´ë ¤ì›€
- **í™•ì¥ì„± ë¶€ì¡±**: ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì •ë³´ì™€ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€

### 2.2 ì§€ì‹ê·¸ë˜í”„ ê¸°ë°˜ ì ‘ê·¼ì˜ ì¥ì 

#### 2.2.1 ì˜ë¯¸ì  ì´í•´
- **ê°œì²´ ì¸ì‹**: ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ê°œë…ë“¤ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ê°œì²´ë¡œ ì¸ì‹
- **ê´€ê³„ íŒŒì•…**: ê°œì²´ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ì—°ê²°
- **ë§¥ë½ ì´í•´**: ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë” ì •í™•í•˜ê²Œ íŒŒì•…

#### 2.2.2 ì •í™•í•œ ë‹µë³€ ìƒì„±
- **ê´€ë ¨ ì •ë³´ ì—°ê²°**: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ê·¸ë˜í”„ë¥¼ í†µí•´ ì—°ê²°
- **ì¶”ë¡  ê°€ëŠ¥**: ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì •ë³´ë„ ê´€ê³„ë¥¼ í†µí•´ ì¶”ë¡ 
- **ì¶œì²˜ ì¶”ì **: ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ì›ë¬¸ì„ ì •í™•íˆ ì¶”ì  ê°€ëŠ¥

#### 2.2.3 ì‹œê°ì  ì´í•´
- **ì§ê´€ì  í‘œí˜„**: ë³µì¡í•œ ì •ë³´ë¥¼ ê·¸ë˜í”„ í˜•íƒœë¡œ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„
- **ê´€ê³„ ì‹œê°í™”**: ë¬¸ì„œ ê°„ì˜ ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥
- **íƒìƒ‰ ìš©ì´**: ê·¸ë˜í”„ë¥¼ í†µí•´ ê´€ë ¨ ì •ë³´ë¥¼ ì‰½ê²Œ íƒìƒ‰ ê°€ëŠ¥

### 2.3 BrainTì˜ ì§€ì‹ê·¸ë˜í”„ í™œìš© ë°©ì‹

#### 2.3.1 ìë™ ì§€ì‹ ì¶”ì¶œ
BrainTëŠ” ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

**1. AI ëª¨ë¸ ê¸°ë°˜ ì¶”ì¶œ (GPT/Ollama)**
```python
# backend/routers/brain_graph.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
async def process_text_endpoint(request_data: ProcessTextRequest):
    text = request_data.text
    source_id = request_data.source_id
    brain_id = request_data.brain_id
    model = request_data.model
    
    # AI ëª¨ë¸ ì„ íƒ
    if model == "gpt":
        ai_service = get_ai_service_GPT()
    elif model == "ollama":
        ai_service = get_ai_service_Ollama()
    
    # í…ìŠ¤íŠ¸ì—ì„œ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ
    nodes, edges = ai_service.extract_graph_components(text, source_id)
    
    # Neo4jì— ê·¸ë˜í”„ ë°ì´í„° ì €ì¥
    neo4j_handler = Neo4jHandler()
    neo4j_handler.insert_nodes_and_edges(nodes, edges, brain_id)
    
    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì„ë² ë”© ì €ì¥
    embedding_service.update_index_and_get_embeddings(nodes, brain_id)
```

**2. ìˆ˜ë™ ì²­í‚¹ ê¸°ë°˜ ì¶”ì¶œ (LDA + TF-IDF)**
```python
# backend/services/manual_chunking_sentences.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def extract_graph_components(text: str, source_id: str):
    # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ ë° í† í°í™”
    tokenized, sentences = split_into_tokenized_sentence(text)
    
    # ì¬ê·€ì  ì²­í‚¹ (LDA ê¸°ë°˜ ì£¼ì œ ëª¨ë¸ë§)
    if len(text) >= 2000:
        chunks, nodes_and_edges, already_made = recurrsive_chunking(
            tokenized, source_id, 0, [], "", 0
        )
        all_nodes = nodes_and_edges["nodes"]
        all_edges = nodes_and_edges["edges"]
    else:
        chunks = [{"chunks": list(range(len(sentences))), "keyword": ""}]
        already_made = []
    
    # ê° ì²­í¬ì—ì„œ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ
    for chunk in chunks:
        if len(chunk["chunks"]) <= 2:
            continue
        relevant_sentences = [sentences[idx] for idx in chunk["chunks"]]
        nodes, edges, already_made = _extract_from_chunk(
            relevant_sentences, source_id, chunk["keyword"], already_made
        )
        all_nodes += nodes
        all_edges += edges
    
    return all_nodes, all_edges
```

#### 2.3.2 ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰
```python
# backend/services/embedding_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def update_index_and_get_embeddings(nodes: List[Dict], brain_id: str):
    collection_name = get_collection_name(brain_id)
    
    # ì—¬ëŸ¬ í¬ë§·ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
    formats = [
        "{name}ëŠ” {label}ì´ë‹¤. {description}",
        "{name} ({label}): {description}",
        "{label}ì¸ {name}ì— ëŒ€í•œ ì„¤ëª…: {description}",
        "{description}"
    ]
    
    for node in nodes:
        for desc in node["descriptions"]:
            description = desc.get("description")
            if not description:
                continue
            
            for idx, fmt in enumerate(formats):
                # í…ìŠ¤íŠ¸ ìƒì„±
                text = fmt.format(
                    name=node["name"], 
                    label=node["label"], 
                    description=description
                )
                
                # ì„ë² ë”© ìƒì„±
                embedding = encode_text(text)
                
                # Qdrantì— ì €ì¥
                client.upsert(
                    collection_name=collection_name,
                    points=[models.PointStruct(
                        id=str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{source_id}_{idx}_{description}")),
                        vector=embedding,
                        payload={
                            "source_id": node["source_id"],
                            "name": node["name"],
                            "label": node["label"],
                            "description": description
                        }
                    )]
                )
```

#### 2.3.3 ê·¸ë˜í”„ ê¸°ë°˜ ë‹µë³€ ìƒì„±
```python
# backend/routers/brain_graph.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
async def answer_endpoint(request_data: AnswerRequest):
    question = request_data.question
    brain_id = str(request_data.brain_id)
    model = request_data.model
    
    # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë…¸ë“œ ì°¾ê¸°
    similar_nodes = embedding_service.search_similar_nodes(
        question, brain_id, top_k=5
    )
    
    # 2. Neo4jì—ì„œ 2ë‹¨ê³„ ê¹Šì´ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
    neo4j_handler = Neo4jHandler()
    graph_schema = neo4j_handler.query_schema_by_node_names(
        [node["name"] for node in similar_nodes], brain_id
    )
    
    # 3. AI ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
    if model == "gpt":
        ai_service = get_ai_service_GPT()
    else:
        ai_service = get_ai_service_Ollama()
    
    answer = ai_service.generate_answer(question, graph_schema)
    
    # 4. ì •í™•ë„ ì ìˆ˜ ê³„ì‚°
    accuracy_score = compute_accuracy(similar_nodes, answer)
    
    return {
        "answer": answer,
        "sources": collect_source_info(similar_nodes),
        "confidence_score": accuracy_score
    }
```

</div>
</details>

<details>
<summary><b>3. ì§€ì‹ê·¸ë˜í”„ ìƒì„± ê³¼ì •</b></summary>
<div markdown="1">

### 3.1 í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë‹¨ê³„

#### 3.1.1 ë¬¸ì„œ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
- **ì§€ì› í˜•ì‹**: PDF, TXT, MD, DOCX ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹
- **í…ìŠ¤íŠ¸ ì •ì œ**: íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬, ì¸ì½”ë”© í†µì¼, ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
- **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**: ë¬¸ì„œ ì œëª©, ì‘ì„±ì, ë‚ ì§œ ë“± ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘

#### 3.1.2 í…ìŠ¤íŠ¸ ì²­í‚¹ (Text Chunking)
```python
def chunk_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 200):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    return text_splitter.split_text(text)
```

#### 3.1.3 ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬
```python
def split_into_sentences(text: str):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return [{"tokens": extract_noun_phrases(sentence), "index": idx} 
            for idx, sentence in enumerate(sentences)]
```

### 3.2 AI ëª¨ë¸ ê¸°ë°˜ ì§€ì‹ ì¶”ì¶œ

#### 3.2.1 í”„ë¡¬í”„íŠ¸ ìƒì„±
BrainTëŠ” AI ëª¨ë¸ì—ê²Œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ì—¬ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤:

```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def _extract_from_chunk(self, chunk: str, source_id: str):
    prompt = (
        "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ ë…¸ë“œì™€ ì—£ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì¤˜. "
        "ë…¸ë“œëŠ” { \"label\": string, \"name\": string, \"description\": string } í˜•ì‹ì˜ ê°ì²´ ë°°ì—´, "
        "ì—£ì§€ëŠ” { \"source\": string, \"target\": string, \"relation\": string } í˜•ì‹ì˜ ê°ì²´ ë°°ì—´ë¡œ ì¶œë ¥í•´ì¤˜. "
        "ì—¬ê¸°ì„œ sourceì™€ targetì€ ë…¸ë“œì˜ nameì„ ì°¸ì¡°í•´ì•¼ í•˜ê³ , source_idëŠ” ì‚¬ìš©í•˜ë©´ ì•ˆ ë¼. "
        "ì¶œë ¥ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ì¤€ìˆ˜í•´ì•¼ í•´:\n"
        "{\n"
        '  "nodes": [ ... ],\n'
        '  "edges": [ ... ]\n'
        "}\n"
        "ë¬¸ì¥ì— ìˆëŠ” ëª¨ë“  ê°œë…ì„ ë…¸ë“œë¡œ ë§Œë“¤ì–´ì¤˜"
        "ê° ë…¸ë“œì˜ descriptionì€ í•´ë‹¹ ë…¸ë“œë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥ì´ì–´ì•¼ í•´. "
        "ë§Œì•½ í…ìŠ¤íŠ¸ ë‚´ì— í•˜ë‚˜ì˜ ê¸´ descriptionì— ì—¬ëŸ¬ ê°œë…ì´ ì„ì—¬ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ê°œë… ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ë…¸ë“œë¥¼ ìƒì„±í•´ì¤˜. "
        "descriptionì€ í•˜ë‚˜ì˜ ê°œë…ì— ëŒ€í•œ ì„¤ëª…ë§Œ ë“¤ì–´ê°€ì•¼ í•´"
        "ë…¸ë“œì˜ labelê³¼ nameì€ í•œê¸€ë¡œ í‘œí˜„í•˜ê³ , ë¶ˆí•„ìš”í•œ ë‚´ìš©ì´ë‚˜ í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ê°€í•˜ì§€ ë§ì•„ì¤˜. "
        "ë…¸ë“œì™€ ì—£ì§€ ì •ë³´ê°€ ì¶”ì¶œë˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ì¶œë ¥í•´ì¤˜.\n\n"
        "json í˜•ì‹ ì™¸ì—ëŠ” ì¶œë ¥ ê¸ˆì§€"
        f"í…ìŠ¤íŠ¸: {chunk}"
    )
    
    resp = chat(
        model=self.model_name,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        stream=False
    )
    content = resp["message"]["content"]
    data = json.loads(content)
```

#### 3.2.2 ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ
```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def extract_graph_components(self, text: str, source_id: str):
    all_nodes, all_edges = [], []
    chunks = chunk_text(text) if len(text) >= 2000 else [text]
    logging.info(f"ì´ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
    
    for idx, chunk in enumerate(chunks, 1):
        logging.info(f"ì²­í¬ {idx}/{len(chunks)} ì²˜ë¦¬")
        nodes, edges = self._extract_from_chunk(chunk, source_id)
        all_nodes.extend(nodes)
        all_edges.extend(edges)
    
    return (
        self._remove_duplicate_nodes(all_nodes),
        self._remove_duplicate_edges(all_edges)
    )
```

#### 3.2.3 ê²€ì¦ ë° í›„ì²˜ë¦¬
```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def _extract_from_chunk(self, chunk: str, source_id: str):
    # ... AI ëª¨ë¸ í˜¸ì¶œ ...
    
    # ë…¸ë“œ ê²€ì¦
    valid_nodes = []
    for node in data.get("nodes", []):
        if not all(k in node for k in ("label", "name")):
            logging.warning("ì˜ëª»ëœ ë…¸ë“œ: %s", node)
            continue
        node.setdefault("descriptions", [])
        node["source_id"] = source_id
        if desc := node.pop("description", None):
            node["descriptions"].append({"description": desc, "source_id": source_id})
        valid_nodes.append(node)

    # ì—£ì§€ ê²€ì¦
    node_names = {n["name"] for n in valid_nodes}
    valid_edges = []
    for edge in data.get("edges", []):
        if all(k in edge for k in ("source", "target", "relation")):
            if edge["source"] in node_names and edge["target"] in node_names:
                valid_edges.append(edge)
            else:
                logging.warning("ì˜ëª»ëœ ì—£ì§€ ì°¸ì¡°: %s", edge)
        else:
            logging.warning("ìŠ¤í‚¤ë§ˆ ëˆ„ë½ ì—£ì§€: %s", edge)
```

### 3.3 ì›ë¬¸ ë§¤ì¹­ ë° ì„ë² ë”© ìƒì„±

#### 3.3.1 ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def _match_original_sentences(self, node: Dict, sentences: List[str]):
    # ë…¸ë“œ ì„¤ëª… ì„ë² ë”© ìƒì„±
    desc_embedding = encode_text(node["description"])
    
    # ëª¨ë“  ë¬¸ì¥ ì„ë² ë”© ìƒì„±
    sentence_embeddings = [encode_text(s) for s in sentences]
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(sentence_embeddings, [desc_embedding])
    
    # threshold ì´ìƒì¸ ë¬¸ì¥ë“¤ ì„ íƒ
    matched_sentences = []
    for i, score in enumerate(similarities.flatten()):
        if score >= 0.8:  # threshold
            matched_sentences.append({
                "original_sentence": sentences[i],
                "source_id": node["source_id"],
                "score": round(float(score), 4)
            })
    
    return matched_sentences
```

#### 3.3.2 ì›ë¬¸ ë¬¸ì¥ ë§¤ì¹­
```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def _extract_from_chunk(self, chunk: str, source_id: str):
    # ... ë…¸ë“œ/ì—£ì§€ ì¶”ì¶œ ...
    
    # ì›ë¬¸ ë¬¸ì¥ ë§¤ì¹­
    sentences = manual_chunking(chunk)
    for node in valid_nodes:
        if node["descriptions"]:
            matched_sentences = self._match_original_sentences(node, sentences)
            node["original_sentences"] = matched_sentences
        else:
            node["original_sentences"] = []
```

### 3.4 ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥

#### 3.4.1 Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
```python
# backend/neo4j_db/Neo4jHandler.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def insert_nodes_and_edges(self, nodes, edges, brain_id):
    def _insert(tx, nodes, edges, brain_id):
        # ë…¸ë“œ ì €ì¥
        for node in nodes:
            # descriptionsë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            new_descriptions = []
            for desc in node.get("descriptions", []):
                if isinstance(desc, dict):
                    new_descriptions.append(json.dumps(desc, ensure_ascii=False))

            # original_sentencesë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            new_originals = []
            for orig in node.get("original_sentences", []):
                if isinstance(orig, dict):
                    new_originals.append(json.dumps(orig, ensure_ascii=False))

            tx.run("""
                MERGE (n:Node {name: $name, brain_id: $brain_id})
                ON CREATE SET
                    n.label = $label,
                    n.brain_id = $brain_id,
                    n.descriptions = $new_descriptions,
                    n.original_sentences = $new_originals
                ON MATCH SET 
                    n.label = $label, 
                    n.brain_id = $brain_id,
                    n.descriptions = CASE 
                        WHEN n.descriptions IS NULL THEN $new_descriptions 
                        ELSE n.descriptions + [item IN $new_descriptions WHERE NOT item IN n.descriptions] 
                    END,
                    n.original_sentences = CASE
                        WHEN n.original_sentences IS NULL THEN $new_originals
                        ELSE n.original_sentences + [item IN $new_originals WHERE NOT item IN n.original_sentences]
                    END
            """, name=node["name"], label=node["label"],
                 new_descriptions=new_descriptions,
                 new_originals=new_originals,
                 brain_id=brain_id)

        # ì—£ì§€ ì €ì¥
        for edge in edges:
            tx.run("""
                MATCH (a:Node {name: $source, brain_id: $brain_id})
                MATCH (b:Node {name: $target, brain_id: $brain_id})
                MERGE (a)-[r:REL {relation: $relation, brain_id: $brain_id}]->(b)
            """, source=edge["source"], target=edge["target"],
                 relation=edge["relation"], brain_id=brain_id)

    with self.driver.session() as session:
        session.execute_write(_insert, nodes, edges, brain_id)
```

#### 3.4.2 Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
```python
# backend/services/embedding_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def update_index_and_get_embeddings(nodes: List[Dict], brain_id: str):
    collection_name = get_collection_name(brain_id)
    
    # ì—¬ëŸ¬ í¬ë§·ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
    formats = [
        "{name}ëŠ” {label}ì´ë‹¤. {description}",
        "{name} ({label}): {description}",
        "{label}ì¸ {name}ì— ëŒ€í•œ ì„¤ëª…: {description}",
        "{description}"
    ]
    
    for node in nodes:
        for desc in node["descriptions"]:
            description = desc.get("description")
            if not description:
                continue
            
            for idx, fmt in enumerate(formats):
                # í…ìŠ¤íŠ¸ ìƒì„±
                text = fmt.format(
                    name=node["name"], 
                    label=node["label"], 
                    description=description
                )
                
                # ì„ë² ë”© ìƒì„±
                embedding = encode_text(text)
                
                # ê³ ìœ  point_id ìƒì„±
                pid = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{source_id}_{idx}_{description}"))
                
                # Qdrantì— ì €ì¥
                client.upsert(
                    collection_name=collection_name,
                    points=[models.PointStruct(
                        id=pid,
                        vector=embedding,
                        payload={
                            "source_id": node["source_id"],
                            "name": node["name"],
                            "label": node["label"],
                            "description": description,
                            "point_id": pid
                        }
                    )]
                )
```

</div>
</details>

<details>
<summary><b>4. ì§€ì‹ê·¸ë˜í”„ í™œìš© ì‚¬ë¡€</b></summary>
<div markdown="1">

### 4.1 ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ

#### 4.1.1 ì˜ë¯¸ì  ê²€ìƒ‰
BrainTëŠ” ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ì„ í†µí•´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë…¸ë“œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤:

```python
# backend/routers/brain_graph.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
async def answer_endpoint(request_data: AnswerRequest):
    question = request_data.question
    brain_id = str(request_data.brain_id)
    model = request_data.model
    
    # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë…¸ë“œ ì°¾ê¸°
    similar_nodes = embedding_service.search_similar_nodes(
        question, brain_id, top_k=5
    )
    
    # 2. Neo4jì—ì„œ 2ë‹¨ê³„ ê¹Šì´ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
    neo4j_handler = Neo4jHandler()
    graph_schema = neo4j_handler.query_schema_by_node_names(
        [node["name"] for node in similar_nodes], brain_id
    )
    
    # 3. AI ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
    if model == "gpt":
        ai_service = get_ai_service_GPT()
    else:
        ai_service = get_ai_service_Ollama()
    
    answer = ai_service.generate_answer(question, graph_schema)
    
    # 4. ì •í™•ë„ ì ìˆ˜ ê³„ì‚°
    accuracy_score = compute_accuracy(similar_nodes, answer)
    
    return {
        "answer": answer,
        "sources": collect_source_info(similar_nodes),
        "confidence_score": accuracy_score
    }
```

#### 4.1.2 ë‹µë³€ ìƒì„± ê³¼ì •
```python
# backend/services/ollama_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def generate_answer(self, question: str, graph_schema: Dict):
    # ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    context = self._build_context_from_schema(graph_schema)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
    ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
    
    ì»¨í…ìŠ¤íŠ¸:
    {context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
    1. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
    2. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ì •ë³´ë“¤
    3. ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì¶”ê°€ ì •ë³´ë“¤
    """
    
    # AI ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
    resp = chat(
        model=self.model_name,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì§€ì‹ ê·¸ë˜í”„ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        stream=False
    )
    
    return resp["message"]["content"]

def _build_context_from_schema(self, graph_schema: Dict) -> str:
    context_parts = []
    
    # ë…¸ë“œ ì •ë³´ ì¶”ê°€
    if "nodes" in graph_schema:
        for node in graph_schema["nodes"]:
            context_parts.append(f"- {node['name']} ({node['label']}): {node.get('description', '')}")
    
    # ê´€ê³„ ì •ë³´ ì¶”ê°€
    if "relationships" in graph_schema:
        for rel in graph_schema["relationships"]:
            context_parts.append(f"- {rel['source']} {rel['relation']} {rel['target']}")
    
    return "\n".join(context_parts)
```

**ì •í™•ë„ ê³„ì‚°:**
```python
# backend/services/accuracy_service.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def compute_accuracy(
    answer: str,
    referenced_nodes: List[str],
    brain_id: str,
    Q: float,  # Retrieval Quality
    raw_schema_text: str,
    w_Q: float = 0.2,  # Retrieval Quality ê°€ì¤‘ì¹˜
    w_S: float = 0.7,  # Semantic Similarity ê°€ì¤‘ì¹˜
    w_C: float = 0.1   # Coverage ê°€ì¤‘ì¹˜
) -> float:
    """
    ë‹µë³€ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        answer: LLMì´ ìƒì„±í•œ ë‹µë³€ í…ìŠ¤íŠ¸
        referenced_nodes: ì°¸ì¡°ëœ ë…¸ë“œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        brain_id: ë¸Œë ˆì¸ ID
        Q: ì´ë¯¸ ê³„ì‚°ëœ Retrieval Quality
        raw_schema_text: ìŠ¤í‚¤ë§ˆ í…ìŠ¤íŠ¸
        w_Q, w_S, w_C: ê° ì§€í‘œì˜ ê°€ì¤‘ì¹˜
    
    Returns:
        ê°€ì¤‘í•© ì •í™•ë„ = w_Q*Q + w_S*S + w_C*C
    """
    # S (Semantic Similarity) ê³„ì‚°
    answer_clean = answer.split("[ì°¸ê³ ëœ ë…¸ë“œ ëª©ë¡]")[0].strip()
    node_names = sorted(set(referenced_nodes))
    
    # Neo4jì—ì„œ ë…¸ë“œ ì„¤ëª… ì¡°íšŒ
    neo4j_handler = Neo4jHandler()
    context_sentences = []
    for name in node_names:
        entries = neo4j_handler.get_node_descriptions(name, brain_id)
        for entry in entries:
            desc = entry.get("description")
            if desc:
                context_sentences.append(f"{name} : {desc}")
    
    # ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ìƒì„± ë° ì„ë² ë”©
    context_text = "\n".join(context_sentences)
    if not context_text:
        S = 0.0
    else:
        answer_vec = encode(answer_clean)
        context_vec = encode(context_text)
        sim = cosine_similarity(
            np.array(answer_vec).reshape(1, -1),
            np.array(context_vec).reshape(1, -1)
        )[0][0]
        S = round(float(sim), 4)
    
    # C (Coverage) ê³„ì‚°
    provided_names = set()
    for segment in raw_schema_text.split("->"):
        segment = segment.strip()
        if "(" not in segment:
            continue
        before_paren = segment.split("(", 1)[0].strip()
        if "-" in before_paren:
            name = before_paren.split("-", 1)[1].strip()
        else:
            name = before_paren.strip()
        name = name.replace(" ", "")
        provided_names.add(name)
    
    ref_names = {n.replace(" ", "") for n in referenced_nodes if isinstance(n, str)}
    C = len(ref_names & provided_names) / len(provided_names) if provided_names else 0.0
    
    # ìµœì¢… ì •í™•ë„ ê³„ì‚°
    Acc = w_Q * Q + w_S * S + w_C * C
    return round(Acc, 3)
```

### 4.2 ì‹œê°í™” ë° íƒìƒ‰

#### 4.2.1 3D ê·¸ë˜í”„ ì‹œê°í™”
- **ë…¸ë“œ í‘œí˜„**: ê° ë…¸ë“œë¥¼ 3D ê³µê°„ì˜ ì ìœ¼ë¡œ í‘œí˜„
- **ì—£ì§€ í‘œí˜„**: ë…¸ë“œ ê°„ì˜ ê´€ê³„ë¥¼ ì„ ìœ¼ë¡œ í‘œí˜„
- **ì¸í„°ë™ì…˜**: ë§ˆìš°ìŠ¤ë¡œ ë…¸ë“œë¥¼ ë“œë˜ê·¸í•˜ì—¬ ìœ„ì¹˜ ì¡°ì • ê°€ëŠ¥

#### 4.2.2 í•˜ì´ë¼ì´íŒ… ê¸°ëŠ¥
- **ê²€ìƒ‰ ê²°ê³¼ í•˜ì´ë¼ì´íŒ…**: ê²€ìƒ‰ëœ ë…¸ë“œë“¤ì„ íŠ¹ë³„í•œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
- **ê´€ê³„ í•˜ì´ë¼ì´íŒ…**: ì„ íƒëœ ë…¸ë“œì™€ ì—°ê²°ëœ ì—£ì§€ë“¤ì„ ê°•ì¡° í‘œì‹œ
- **ê²½ë¡œ í•˜ì´ë¼ì´íŒ…**: ë‘ ë…¸ë“œ ê°„ì˜ ìµœë‹¨ ê²½ë¡œë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ

### 4.3 ì§€ì‹ ë¶„ì„ ë° í†µì°°

#### 4.3.1 ì¤‘ì‹¬ì„± ë¶„ì„
BrainTëŠ” Neo4jì˜ ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ë…¸ë“œì˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤:

```python
# backend/neo4j_db/Neo4jHandler.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def analyze_centrality(self, brain_id: str):
    centrality_query = """
    MATCH (n:Node {brain_id: $brain_id})
    WITH n
    CALL gds.pageRank.stream('graph')
    YIELD nodeId, score
    WHERE gds.util.asNode(nodeId) = n
    RETURN n.name as node_name, score as pagerank
    ORDER BY pagerank DESC
    LIMIT 10
    """
    
    with self.driver.session() as session:
        result = session.run(centrality_query, brain_id=brain_id)
        return [record.data() for record in result]

def get_most_connected_nodes(self, brain_id: str, limit: int = 10):
    query = """
    MATCH (n:Node {brain_id: $brain_id})-[r:RELATES_TO]-(other)
    RETURN n.name as node_name, count(r) as connection_count
    ORDER BY connection_count DESC
    LIMIT $limit
    """
    
    with self.driver.session() as session:
        result = session.run(query, brain_id=brain_id, limit=limit)
        return [record.data() for record in result]
```

#### 4.3.2 ì»¤ë®¤ë‹ˆí‹° íƒì§€
```python
# backend/neo4j_db/Neo4jHandler.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
def detect_communities(self, brain_id: str):
    # Louvain ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì»¤ë®¤ë‹ˆí‹° íƒì§€
    community_query = """
    CALL gds.louvain.stream('graph')
    YIELD nodeId, communityId
    MATCH (n:Node {brain_id: $brain_id})
    WHERE gds.util.asNode(nodeId) = n
    RETURN n.name as node_name, communityId
    ORDER BY communityId, node_name
    """
    
    with self.driver.session() as session:
        result = session.run(community_query, brain_id=brain_id)
        communities = defaultdict(list)
        for record in result:
            communities[record["communityId"]].append(record["node_name"])
        return dict(communities)
```

#### 4.3.3 ì§€ì‹ ë°€ë„ ë¶„ì„
```python
# backend/routers/brain_graph.py - ì‹¤ì œ í”„ë¡œì íŠ¸ ì½”ë“œ
async def get_source_data_metrics(brain_id: str):
    """ë¸Œë ˆì¸ì˜ ì†ŒìŠ¤ë³„ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        sqlite_handler = SQLiteHandler()
        neo4j_handler = Neo4jHandler()
        
        # ì†ŒìŠ¤ë³„ í…ìŠ¤íŠ¸ ì–‘ ê³„ì‚°
        source_metrics = {}
        sources = sqlite_handler.get_all_sources_by_brain_id(brain_id)
        
        for source in sources:
            source_id = source["source_id"]
            text_content = sqlite_handler.get_source_content(source_id, brain_id)
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
            text_length = len(text_content) if text_content else 0
            
            # ë…¸ë“œ ê°œìˆ˜ ê³„ì‚°
            nodes = neo4j_handler.get_nodes_by_source_id(source_id, brain_id)
            node_count = len(nodes) if nodes else 0
            
            # ì—£ì§€ ê°œìˆ˜ ê³„ì‚°
            edges = neo4j_handler.get_edges_by_source_id(source_id, brain_id)
            edge_count = len(edges) if edges else 0
            
            source_metrics[source_id] = {
                "title": source["title"],
                "text_length": text_length,
                "node_count": node_count,
                "edge_count": edge_count,
                "knowledge_density": node_count / max(text_length, 1) * 1000  # 1000ìë‹¹ ë…¸ë“œ ìˆ˜
            }
        
        return source_metrics
        
    except Exception as e:
        logging.error(f"ì†ŒìŠ¤ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail="ì†ŒìŠ¤ ë°ì´í„° ë©”íŠ¸ë¦­ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
```

### 4.4 ì§€ì‹ í™•ì¥ ë° ì—°ê²°

#### 4.4.1 ìƒˆë¡œìš´ ë¬¸ì„œ í†µí•©
- **ê¸°ì¡´ ë…¸ë“œì™€ì˜ ë§¤ì¹­**: ìƒˆë¡œìš´ ë¬¸ì„œì˜ ë…¸ë“œë“¤ì„ ê¸°ì¡´ ë…¸ë“œì™€ ë§¤ì¹­
- **ìƒˆë¡œìš´ ë…¸ë“œ ì¶”ê°€**: ë§¤ì¹­ë˜ì§€ ì•Šì€ ë…¸ë“œë“¤ì„ ìƒˆë¡œìš´ ë…¸ë“œë¡œ ì¶”ê°€
- **ê´€ê³„ ì—…ë°ì´íŠ¸**: ê¸°ì¡´ ë…¸ë“œì™€ ìƒˆë¡œìš´ ë…¸ë“œ ê°„ì˜ ê´€ê³„ ìƒì„±

#### 4.4.2 ì™¸ë¶€ ì§€ì‹ ì—°ê²°
- **ìœ„í‚¤í”¼ë””ì•„ ì—°ë™**: ë…¸ë“œì™€ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ ì—°ê²°
- **í•™ìˆ  ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™**: ì—°êµ¬ ë…¼ë¬¸ê³¼ í•™ìˆ  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
- **ë‰´ìŠ¤ ë°ì´í„° ì—°ë™**: ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë°ì´í„°ì™€ ì—°ê²°

</div>
</details>

<details>
<summary><b>5. ì§€ì‹ê·¸ë˜í”„ì˜ í•œê³„ì™€ ê°œì„  ë°©í–¥</b></summary>
<div markdown="1">

### 5.1 í˜„ì¬ í•œê³„ì 

#### 5.1.1 ê¸°ìˆ ì  í•œê³„
- **AI ëª¨ë¸ ì˜ì¡´ì„±**: ì§€ì‹ ì¶”ì¶œì˜ ì •í™•ë„ê°€ AI ëª¨ë¸ì˜ ì„±ëŠ¥ì— í¬ê²Œ ì˜ì¡´
- **ì–¸ì–´ íŠ¹í™”**: í•œêµ­ì–´ì— íŠ¹í™”ë˜ì–´ ìˆì–´ ë‹¤êµ­ì–´ ì§€ì›ì´ ì œí•œì 
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ ì‹œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ê·¸ë˜í”„ê°€ ì»¤ì§ˆìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê¸‰ì¦

#### 5.1.2 í’ˆì§ˆ ê´€ë ¨ í•œê³„
- **ë…¸ë“œ ì¶”ì¶œ ì •í™•ë„**: AI ëª¨ë¸ì´ ëª¨ë“  ì¤‘ìš”í•œ ê°œë…ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì§€ ëª»í•¨
- **ê´€ê³„ ì¶”ì¶œ ì •í™•ë„**: ë…¸ë“œ ê°„ì˜ ê´€ê³„ë¥¼ ì˜ëª» í•´ì„í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
- **ì¤‘ë³µ ë…¸ë“œ**: ë™ì¼í•œ ê°œë…ì´ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì¶”ì¶œë˜ëŠ” ê²½ìš°
- **ë…¸ì´ì¦ˆ**: ë¶ˆí•„ìš”í•œ ì •ë³´ê°€ ë…¸ë“œë¡œ ì¶”ì¶œë˜ëŠ” ê²½ìš°

### 5.2 ê°œì„  ë°©í–¥

#### 5.2.1 ê¸°ìˆ ì  ê°œì„ 
- **ë‹¤ì¤‘ AI ëª¨ë¸ ì•™ìƒë¸”**: ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
- **ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸**: ë„ë©”ì¸ íŠ¹í™” ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ê°œë°œ
- **ì¦ë¶„ í•™ìŠµ**: ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ 
- **ë¶„ì‚° ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¶„ì‚° ì‹œìŠ¤í…œ êµ¬ì¶•

#### 5.2.2 í’ˆì§ˆ ê°œì„ 
- **ì‚¬í›„ ê²€ì¦**: ì¶”ì¶œëœ ë…¸ë“œ/ì—£ì§€ì˜ í’ˆì§ˆì„ ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ
- **ì‚¬ìš©ì í”¼ë“œë°±**: ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„ ê°œì„ 
- **ë„ë©”ì¸ ì§€ì‹ í†µí•©**: íŠ¹ì • ë„ë©”ì¸ì˜ ì „ë¬¸ ì§€ì‹ì„ ì‚¬ì „ì— ì •ì˜
- **ë™ì  ì—…ë°ì´íŠ¸**: ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì‹œìŠ¤í…œ

#### 5.2.3 ì‚¬ìš©ì„± ê°œì„ 
- **ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤**: ì‚¬ìš©ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‹œê°í™”
- **ê°œì¸í™”**: ì‚¬ìš©ìë³„ ë§ì¶¤í˜• ì§€ì‹ ê·¸ë˜í”„ ì œê³µ
- **í˜‘ì—… ê¸°ëŠ¥**: ì—¬ëŸ¬ ì‚¬ìš©ìê°€ í•¨ê»˜ ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•
- **ëª¨ë°”ì¼ ì§€ì›**: ëª¨ë°”ì¼ í™˜ê²½ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤

### 5.3 í–¥í›„ ì—°êµ¬ ë°©í–¥

#### 5.3.1 í•™ìˆ ì  ì—°êµ¬
- **ì§€ì‹ ê·¸ë˜í”„ í’ˆì§ˆ í‰ê°€**: ê°ê´€ì ì¸ í’ˆì§ˆ í‰ê°€ ì§€í‘œ ê°œë°œ
- **ë‹¤êµ­ì–´ ì§€ì‹ ê·¸ë˜í”„**: ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ” í†µí•© ì§€ì‹ ê·¸ë˜í”„
- **ì‹œë§¨í‹± ì›¹ ì—°ë™**: ì›¹ í‘œì¤€ê³¼ í˜¸í™˜ë˜ëŠ” ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•
- **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ í†µí•œ ì‹¤ì‹œê°„ í•™ìŠµ

#### 5.3.2 ì‚°ì—… ì ìš©
- **ê¸°ì—… ì§€ì‹ ê´€ë¦¬**: ê¸°ì—… ë‚´ë¶€ ì§€ì‹ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬
- **êµìœ¡ í”Œë«í¼**: êµìœ¡ìš© ì§€ì‹ ê·¸ë˜í”„ ê¸°ë°˜ í•™ìŠµ ì‹œìŠ¤í…œ
- **ì˜ë£Œ ì§„ë‹¨**: ì˜í•™ ì§€ì‹ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•œ ì§„ë‹¨ ì§€ì› ì‹œìŠ¤í…œ
- **ë²•ë¥  ìë¬¸**: ë²•ë¥  ì§€ì‹ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•œ ìë¬¸ ì‹œìŠ¤í…œ

</div>
</details>

<br/>
<br/>

## ğŸ“– ì°¸ê³  ìë£Œ

- **Neo4j Graph Database**: https://neo4j.com/
- **Knowledge Graph Conference**: https://www.knowledgegraph.tech/
- **Google Knowledge Graph**: https://developers.google.com/knowledge-graph
- **Wikipedia Knowledge Graph**: https://www.wikidata.org/
- **DBpedia**: https://dbpedia.org/
- **YAGO**: https://yago-knowledge.org/

## ğŸ”— ê´€ë ¨ ë§í¬

- [BrainT í”„ë¡œì íŠ¸ README](./README.md)
- [ì§€ì‹ê·¸ë˜í”„ ìƒì„± ë¡œì§ ìƒì„¸ ë¶„ì„](./KNOWLEDGE_GRAPH_GENERATION.md)
- [AI ëª¨ë¸ í†µí•© ê°€ì´ë“œ](./AI_MODEL_INTEGRATION.md) 